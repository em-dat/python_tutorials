{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4fa5311",
   "metadata": {},
   "source": [
    "# Making Maps\n",
    "\n",
    "If you have followed the [EM-DAT Python Tutorial 1](./python_tutorial_1_basic_operations_and_plotting.ipynb) or are already familiar with [`pandas`](https://pandas.pydata.org/) and [`matplotlib`](https://matplotlib.org/), this second tutorial will show you basic examples on how to make maps with the EM-DAT data using the [`geopandas`](https://geopandas.org/en/stable/) Python package.\n",
    "\n",
    "**Note**: This tutorial is also available on the [EM-DAT Documentation Website](https://doc.emdat.be/docs/additional-resources-and-tutorials/tutorials/python_tutorial_2/).\n",
    "\n",
    "## Import Modules\n",
    "\n",
    "Let us import the necessary modules and print their versions. For this tutorial, we used `pandas` v.2.1.1, `geopandas` v.0.14.3, and `matplotlib` v.3.8.3. If your package versions are different, you may have to adapt this tutorial by checking the corresponding package documentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4025a08-1245-475e-b13e-24a378896118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #data analysis package\n",
    "import geopandas as gpd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt #plotting library\n",
    "for i in [pd, gpd, mpl]:\n",
    "    print(i.__name__, i.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4e7102-2c82-449a-9211-cba28b01c24f",
   "metadata": {},
   "source": [
    "## Creating a World Map\n",
    "\n",
    "To create a world map, we need the EM-DAT data and a shapefile containing the country geometries.\n",
    "\n",
    "**EM-DAT**: We download and load the EM-DAT data using `pandas`. \n",
    "\n",
    "**Country Shapefile**: We download a country shapefile from [Natural Earth Data](https://www.naturalearthdata.com/). For a world map, we download the low resolution [1:110m Adimin 0 - Countries](https://www.naturalearthdata.com/downloads/110m-cultural-vectors/) (last accessed: March 10, 2024) and unzip it. \n",
    "\n",
    "### Load and Filter EM-DAT\n",
    "\n",
    "Let us load EM-DAT and filter it to make a global map of Earthquake disasters between 2000 and 2023. We calculate the number of unique identifiers (`DisNo.`) per country (`ISO`) We refer to the standard `ISO` column instead of the `Country` column of the [EM-DAT Public Table](https://doc.emdat.be/docs/data-structure-and-content/emdat-public-table/) to be able to make a join with the country shapefile.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00198567-90e3-4bf4-88c7-de843389df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('public_emdat_2024-01-08.xlsx')\n",
    "earthquake_counts = df[\n",
    "    (df['Disaster Type'] == 'Earthquake') &\n",
    "    (df['Start Year'] < 2024)\n",
    "].groupby('ISO')[\"DisNo.\"].count().reset_index(name='EarthquakeCount')\n",
    "earthquake_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1862cc8-5f54-4520-9c06-2f89945f4838",
   "metadata": {},
   "source": [
    "### Load the Country Shapefile\n",
    "\n",
    "We use the [`gpd.read_file`](https://geopandas.org/en/stable/docs/reference/api/geopandas.read_file.html) method to load the country shapefile and parse it into a geodataframe. A geodataframe is similar to a `pandas` dataframe, extept that has a geometry column.\n",
    "\n",
    "We provide the `filename` argument, which is either a file name if located in the same directory than the running script, or a relative or absolute path, if not. In our case the shapefile with the `.shp` extension is located in the `ne_110m_admin_0_countries` folder.\n",
    "\n",
    "Since the geodataframe contains 169 columns, we only keep the two column that we are interrested in, i.e., `ISO_A3` and `geometry`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f75c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file ('ne_110m_admin_0_countries/ne_110m_admin_0_countries.shp') # <-- Change path if necessary\n",
    "gdf = gdf[['ISO_A3', 'geometry']]\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916d78b2-a09f-4820-952e-8f4491bb42fa",
   "metadata": {},
   "source": [
    "**Important Notice**: Above, some geometries do not have a ISO code, such as the one at row 174. Below, you will see that some ISO in EM-DAT are not matched with a geometries. Beyond this basic tutorial, we advice to carefully evaluate these correspondance and non-correspondance between ISO codes and to read the [EM-DAT Documentation about ISO codes](https://doc.emdat.be/docs/data-structure-and-content/spatial-information/).\n",
    "\n",
    "### Join the Two Datasets\n",
    "\n",
    "Let us merge the two dataset with an outer join, using the [`merge`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html#pandas.DataFrame.merge) method. We prefer an `outer` join to keep the geometries of countries for which EM-DAT has no records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c9620f-2f3c-483f-924b-34bad67cba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquake_counts_with_geom = gdf.merge(\n",
    "    earthquake_counts, left_on='ISO_A3', right_on='ISO', how='outer')\n",
    "earthquake_counts_with_geom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79414fc-0c5a-49a7-bdc8-f456afb5b6f5",
   "metadata": {},
   "source": [
    "### Make the Map\n",
    "\n",
    "To make the map, we use the `geopandas` built-in API, through the [`plot`](https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.plot.html) method built on the top of `matplotlib`. \n",
    "Below, we show an hybrid plotting approach and first create an empty figure `fig` and `ax` object with matplotlib before passing the `ax` object as an argument within the `plot` method. This approach gives more control to users familiar with `matplotlib` to further customize the chart. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad5e8d-7dd0-4aca-bf80-4a4236506e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,3))\n",
    "earthquake_counts_with_geom.plot(\n",
    "    column='EarthquakeCount',\n",
    "    ax=ax,\n",
    "    cmap='Reds',\n",
    "    vmin=1,\n",
    "    legend=True,\n",
    "    legend_kwds={\"label\": \"Nb of EM-DAT Earthquake\"},\n",
    "    missing_kwds= dict(color = \"lightgrey\",)\n",
    ")\n",
    "_ = ax.set_xlabel('Lon.')\n",
    "_ = ax.set_ylabel('Lat.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e9604-d6b6-414d-afbf-67e4efb3c356",
   "metadata": {},
   "source": [
    "## Creating a Map at Admin Level 1\n",
    "\n",
    "We can create a more detailed map using the `Admin Units` column in the [EM-DAT Public Table](https://doc.emdat.be/docs/data-structure-and-content/emdat-public-table/). This column contains the identifiers of administrative units of level 1or 2 as defined by the Global Administrative Unit Layer (GAUL) for country impacted by non-biological natural hazards. \n",
    "\n",
    "Similarly to the country map, we need to download [a file containing GAUL geometries](https://files.emdat.be/data/gaul_gpkg_and_license.zip). The file corresponds to the last version of GAUL published in 2015. In this tutorial, we will focus on Japanese earthquake occurrence in EM-DAT.\n",
    "\n",
    "**Note**: the file size is above 1.3Go and requires a performant computer to process in Python. Using a Geographical Information Software (GIS) for the preprocessing is another option. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa89b6-25b7-4233-928e-e3793505ad05",
   "metadata": {},
   "source": [
    "### Load the Admin Units Geopackage\n",
    "\n",
    "The file is a geopackage `.gpkg` that contains multiple layers. Let us first describe these layers with the `fiona` package, which is a `geopandas` dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156c231d-4253-4c2a-aeac-60975cb86186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "print(fiona.__name__, fiona.__version__)\n",
    "for layername in fiona.listlayers('gaul2014_2015.gpkg'):\n",
    "    with fiona.open('gaul2014_2015.gpkg', layer=layername) as src:\n",
    "        print(layername, len(src))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32b1964-55f9-44cc-bb88-8490278b6ab6",
   "metadata": {},
   "source": [
    "* The `level0` layer contains the country geometries defined in GAUL.\n",
    "* Here, we make a map at the `level1`.\n",
    "* Still, we need to load the administrative `level2` because the `Admin Units` column may refer to Admin 2 levels without mentionning the corresponding Admin 1 level.\n",
    "* Given the high size the admin 2 layer, we filter the data about Japan and overwrite our geodataframe variable to save memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01418e0f-2f77-4529-be54-1394625850d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaul_adm2 = gpd.read_file ('gaul2014_2015.gpkg', layer='level2') \n",
    "gaul_adm2 = gaul_adm2[gaul_adm2['ADM0_NAME'] == 'Japan']\n",
    "gaul_adm2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b84e79a-ae96-4037-970b-bbd48ce81628",
   "metadata": {},
   "source": [
    "The Admin 2 geodataframe has 12 columns describing the 3348 level 2 administrative units in Japan. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ce4833-1315-4aa0-84b8-164b6757af35",
   "metadata": {},
   "source": [
    "### Filter EM-DAT Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6328cf17-ed1c-4a77-a266-3bf0503da52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jpn = df[\n",
    "    (df['ISO'] == 'JPN') &\n",
    "    (df['Disaster Type'] == 'Earthquake') &\n",
    "    (df['Start Year'] < 2024)\n",
    "][['DisNo.', 'Admin Units']]\n",
    "df_jpn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725ef6ce-6e2b-4400-b6f1-6d9094508b2d",
   "metadata": {},
   "source": [
    "**Note**: The last two events were not geolocated at a higher administrative levels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb10d2-92f3-41fa-aad5-75ff99b291f5",
   "metadata": {},
   "source": [
    "### Convert Admin 2 units to Admin 1 units\n",
    "\n",
    "We create a python function, `json_to_amdmin1`, to extract the administrative level 1 codes from the `Admin Units` column of EM-DAT, based on the `ADM1_CODE` and `ADM2_CODE` of the Japan geodataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47659611-a497-4371-9b6c-5b3948f4e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def json_to_admin1(json_str, gdf):\n",
    "    \"\"\"\n",
    "    Convert a JSON string to a set of administrative level 1 codes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    json_str\n",
    "        A JSON string representing administrative areas, or None.\n",
    "    gdf\n",
    "        A GeoDataFrame containing administrative codes and their corresponding \n",
    "        levels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A set of administrative level 1 (ADM1) codes extracted from the input JSON.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If the administrative code is missing from the input data or ADM2_CODE \n",
    "        not found in the provided GeoDataFrame.\n",
    "\n",
    "    \"\"\"\n",
    "    adm_list = json.loads(json_str) if isinstance(json_str, str) else None\n",
    "    adm1_list = []\n",
    "    if adm_list is not None:\n",
    "        for entry in adm_list:\n",
    "            if 'adm1_code' in entry.keys():\n",
    "                adm1_code = entry['adm1_code']\n",
    "            elif 'adm2_code' in entry.keys():\n",
    "                gdf_sel = gdf[gdf['ADM2_CODE'] == entry['adm2_code']]\n",
    "                if not gdf_sel.empty:\n",
    "                    adm1_code = gdf_sel.iloc[0]['ADM1_CODE']\n",
    "                else:\n",
    "                    raise ValueError(\n",
    "                        'ADM2_CODE not found in the provided GeoDataFrame.'\n",
    "                    )\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    'Administrative code is missing from the provided data.'\n",
    "                )\n",
    "            adm1_list.append(adm1_code)\n",
    "    return set(adm1_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c844d8-3273-4cf7-ac4c-1043ee89a577",
   "metadata": {},
   "source": [
    "We apply the function to all elements of the `Admin Units` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38883e2c-1dbe-452e-9ce1-04d7bbc05409",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jpn.loc[:, 'Admin_1'] = df_jpn['Admin Units'].apply(\n",
    "    lambda x: json_to_admin1(x, gaul_adm2))\n",
    "\n",
    "df_jpn[['Admin Units', 'Admin_1']] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dbcc57-4dd4-43d8-a356-f606d04454d7",
   "metadata": {},
   "source": [
    "### Count Earthquakes per Admin 1 Units\n",
    "\n",
    "The can be done applying the [`explode`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.explode.html) method on the new `Admin_1` column. The method will add rows based on the number of Admin 1 we have in each set inside the `Admin_1` column. Then the counting can be performed using the former `groupby` approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901ba404-9970-441a-9d1e-59ac52e33dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_per_adm1 = df_jpn.explode('Admin_1').groupby(\n",
    "    'Admin_1')['DisNo.'].count().rename('EQ Count')\n",
    "count_per_adm1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54dc85a-5ca9-4068-bcf0-72ee2a0e0901",
   "metadata": {},
   "source": [
    "### Recreate the Admin 1 Layer\n",
    "\n",
    "Since the Japan geodataframe contains the admin2 geometries, we could load the Admin 1 layer or simply dissolve the geometries based on the `ADM1_CODE` column. The `geopandas` package is equipped with the [`dissolve`](https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.dissolve.html) method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22b29be-b608-4007-81ef-cb9e4489c5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_jpn_adm1 = gaul_adm2.dissolve(by='ADM1_CODE') \n",
    "gdf_jpn_adm1.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27444ab-dd80-4c23-9782-b78b723ab276",
   "metadata": {},
   "source": [
    "### Join the Two Datasets\n",
    "\n",
    "Again, we can use the [`merge`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html#pandas.DataFrame.merge) method to join the datasets together, here, based on their index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c16eb41-6398-404d-a5ac-c5fe880eb380",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_jpn_adm1_merged = gdf_jpn_adm1.merge(count_per_adm1, \n",
    "                                         left_index=True, \n",
    "                                         right_index=True, \n",
    "                                         how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e057b8-f8f3-45ae-9f96-1b4af46674d1",
   "metadata": {},
   "source": [
    "### Make the Map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c8c8c3-0305-4182-a745-acd4e0dde22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "gdf_jpn_adm1_merged.plot(\n",
    "    column='EQ Count', cmap='YlOrRd',\n",
    "    linewidth=0.8, ax=ax,edgecolor='0.8',\n",
    "    legend=True, \n",
    "    legend_kwds={'label': \"Earthquake Count in EM-DAT\"}\n",
    ")\n",
    "_ = ax.set_xlabel('Longitude')\n",
    "_ = ax.set_ylabel('Latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b5ba57-e42e-49ff-90bc-b983b6208688",
   "metadata": {},
   "source": [
    "We have just covered the basics on how to join the EM-DAT [`pandas`](https://pandas.pydata.org/pandas-docs/stable/) `DataFrame` with  a [`geopandas`](https://geopandas.org/en/stable/) `GeoDataFrame` to make maps. To delve further into your analyses, we encourage you to continue your learning of [`geopandas`](https://geopandas.org/en/stable/),  [`matplotlib`](https://matplotlib.org/stable/contents.html), or, in particular, [`cartopy`](https://scitools.org.uk/cartopy/docs/latest/) for more advanced map customization, with the many resources available online."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
